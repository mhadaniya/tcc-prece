\chapter{Introdução}%%Inserir título do capítulo (nível 1)
\indent A constante expansão na utilização da Internet tornou a rede um serviço essencial para a interconexão global, e para as empresas também. A cada dia há um crescimento na demanda por novos serviços, que necessitam de políticas de segurança que mantenham a integridade e a privacidade dos dados. Isso torna os sistemas cada vez mais complexos e os dados cada vez mais heterogêneos, impossibilitando que a gerência da rede seja realizada por um operador humano. Devido à esta dificuldade de gerência, surgem comportamentos que fogem dos padrões normais do tráfego, estes comportamentos são as anomalias. Uma anomalia pode ser definida como uma não conformidade com o comportamento normal de uma determinada base de dados. As anomalias podem ser geradas por vários fatores, podendo ser maliciosas, como, ataques de negação de serviço (DoS - \textit{Deny of Service}), exércitos de máquinas controladas sem autorização (\textit{botnets}) e envio massivo de correio eletrônico (\textit{spam}). E podem não ser maliciosas, como, interrupções não planejadas, crescimento repentino de tráfego, e erros de configurações.

\indent A detecção de anomalias em redes é uma tarefa extremamente difícil, principalmente porque as anomalias são alvos móveis presentes em um conjunto muito grande de dados heterogêneos, que abrangem diversos tipos de serviços sendo utilizados, várias portas de entrada e saídas, e muitos usuários. Isso dificulta a precisão em encontrar um determinado conjunto de dados do tráfego que caracterizam uma anomalia. Além disso, para classificar uma anomalia é necessário conhecer o seu perfil, e a dificuldade desta tarefa aumenta a cada dia com o surgimento de novas tecnologias, novos tipos de ataques e técnicas de invasão.

\indent Há várias abordagens propostas na literatura para a detecção de anomalias que abrangem desde métodos estatísticos à técnicas de aprendizado de máquina. De maneira geral, os estudos classificam a detecção de anomalias em duas vertentes, a baseada no comportamento normal da rede, que busca definir um perfil do tráfego normal e classifica como anomalia todos os dados que se diferem deste perfil. E a detecção baseada em assinaturas, que possui uma base da dados com a assinatura de várias anomalias e consegue verificar a semelhança entre os dados da rede e estas assinaturas.

\indent O objetivo deste trabalho é apresentar os principais métodos de detecção de anomalias presentes na literatura, relatar os benefícios de cada abordagem e em quais situações apresentam melhores resultados. Além disso, é realizado um estudo com ênfase no algoritmo de agrupamento K-means, uma abordagem simplificada e eficaz, muito explorada literatura. Deste modo, serão realizados vários experimentos demonstrando a utilização do algoritmo sendo aplicado na base de dados KDDcup99, onde, será possível avaliar o algoritmo em várias situações.
